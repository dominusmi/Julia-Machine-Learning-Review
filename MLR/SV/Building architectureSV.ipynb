{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: deprecated syntax \"abstract AvgMode\" at /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/averagemode.jl:10.\n",
      "Use \"abstract type AvgMode end\" instead.\n",
      "\n",
      "WARNING: deprecated syntax \"abstract AbstractBinary\" at /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/classification/comparemode.jl:17.\n",
      "Use \"abstract type AbstractBinary end\" instead.\n",
      "\n",
      "WARNING: deprecated syntax \"abstract AbstractMultiClass\" at /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/classification/comparemode.jl:49.\n",
      "Use \"abstract type AbstractMultiClass end\" instead.\n",
      "\n",
      "WARNING: deprecated syntax \"inner constructor MultiClass(...) around /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/classification/comparemode.jl:66\".\n",
      "Use \"MultiClass{T,N}(...) where {T,N}\" instead.\n",
      "WARNING: Method definition auto(Bool, Bool) in module CompareMode at /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/classification/comparemode.jl:100 overwritten at /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/classification/comparemode.jl:107.\n",
      "WARNING: Method definition auto(Bool, Bool) in module CompareMode at /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/classification/comparemode.jl:107 overwritten at /Applications/JuliaPro-0.6.2.1.app/Contents/Resources/pkgs-0.6.2.1/v0.6/MLMetrics/src/classification/comparemode.jl:108.\n"
     ]
    }
   ],
   "source": [
    "import StatsBase: predict\n",
    "import Base: getindex, show\n",
    "import MLBase: Kfold\n",
    "using MLMetrics\n",
    "using SparseRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fakedata (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Fakedata(N,d)\n",
    "    n_obs = 100\n",
    "    x = randn((n_obs,d))\n",
    "    y = sum(x*randn(d),2)\n",
    "    \n",
    "    hcat(x,y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×4 Array{Float64,2}:\n",
       "  0.0973409  -0.426206   -2.20467     1.15517  \n",
       "  1.09764    -2.23121    -1.22836    -2.37771  \n",
       " -0.0911682   2.04924    -0.969256    4.05808  \n",
       " -0.149748   -2.73146    -0.570739   -3.91302  \n",
       " -0.223951    1.1719      0.788278    1.18538  \n",
       " -1.48807    -1.0224     -0.914728   -1.10797  \n",
       "  0.854177   -0.355109    1.13253    -1.36962  \n",
       "  0.910098    1.13904     0.275291    1.73251  \n",
       "  0.497604    0.238259    0.499603    0.0450758\n",
       "  0.829776   -0.268876   -0.193977   -0.140337 \n",
       " -2.43997     1.57523    -0.898356    2.87821  \n",
       " -0.67792     0.364261   -1.22959     1.49173  \n",
       "  0.183108   -0.392075    0.771805   -1.23491  \n",
       "  ⋮                                            \n",
       "  1.82227     0.456899    0.400614    0.681478 \n",
       "  0.190407    1.18768    -0.711358    2.51324  \n",
       "  1.10039     0.393971    0.0269222   0.777559 \n",
       "  0.663291   -0.501412   -0.278055   -0.468015 \n",
       " -0.650657   -0.0870616  -0.425518    0.111399 \n",
       "  0.428484   -0.592906   -0.182926   -0.729092 \n",
       " -0.840298   -0.661935   -2.10342     0.54967  \n",
       "  3.01867    -1.24515    -0.820056   -0.842376 \n",
       " -0.823303    2.36759     0.69181     3.08108  \n",
       " -0.769791    0.0130985   0.994138   -0.919479 \n",
       "  1.20566     0.530232    0.146575    0.912647 \n",
       "  0.158747   -0.0159117  -1.37712     1.13641  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fakedata(1000,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "immutable Task \n",
    "    task_type::String\n",
    "    target::Int\n",
    "    features::Array{Int}\n",
    "end\n",
    "\n",
    "function Task(;task_type=\"regression\", target=nothing, data=nothing)\n",
    "    if target == nothing || data == nothing\n",
    "        throw(\"Requires target and data to be set\")\n",
    "    end\n",
    "    \n",
    "    features = size(data,2)\n",
    "    features = deleteat!( collect(1:features), target)\n",
    "    \n",
    "    Task(task_type, target, features)\n",
    "end\n",
    "\n",
    "immutable Learner\n",
    "    name::String\n",
    "    parameters::Union{Void,Dict{Any}}\n",
    "    Learner(learner::String) = new(learner, Dict())\n",
    "    Learner(learner::String, parameters::Dict{Any}) = new(learner, parameters)\n",
    "end\n",
    "\n",
    "function show(io::IO,l::Learner)\n",
    "    println(\"Learner: $(l.name)\")\n",
    "    for (key, value) in l.parameters\n",
    "       println(\" ▁ ▂ ▃ $key: $value\") \n",
    "    end\n",
    "end\n",
    "\n",
    "immutable Resampling\n",
    "    method::String\n",
    "    iterations::Int\n",
    "    Resampling() = new(\"KFold\", 3)\n",
    "end\n",
    "\n",
    "abstract type Parameter end\n",
    "\n",
    "immutable DiscreteParameter <: Parameter \n",
    "    name::String\n",
    "    values::Array{Any}\n",
    "    DiscreteParameter(;name=nothing,values=nothing) = new(name, values)\n",
    "end\n",
    "\n",
    "immutable ContinuousParameter <: Parameter\n",
    "    name::String\n",
    "    lower::Real\n",
    "    upper::Real\n",
    "    transform::Function\n",
    "    ContinuousParameter(;name=nothing, lower=nothing, upper=nothing, transform=nothing) = new(name, lower, upper, transform)\n",
    "end\n",
    "\n",
    "\n",
    "immutable ParametersSet\n",
    "   parameters::Array{Parameter}\n",
    "end\n",
    "\n",
    "getindex(p::ParametersSet, i::Int64) = p.parameters[i]\n",
    "\n",
    "immutable MLRModel{T}\n",
    "    model::T\n",
    "    parameters\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learnᵧ (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### ABSTRACT FUNCTIONS ####\n",
    "\n",
    "function MLRModel(learner::Learner, task::Task, data)\n",
    "    # Calls function with name \"makeModelname\"\n",
    "    f_name = learner.name\n",
    "    f_name = \"make\" * titlecase(f_name)\n",
    "    \n",
    "    f = getfield(Main, Symbol(f_name))\n",
    "    f(learner, task, data)\n",
    "end    \n",
    "\n",
    "function learnᵧ(learner::Learner, task::Task, data)\n",
    "    modelᵧ = MLRModel(learner, task, data)\n",
    "    learnᵧ!(modelᵧ, learner=learner, task=task, data=data)\n",
    "    modelᵧ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "makeGlm (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TRANSITION ###\n",
    "function makeRidge(learner::Learner, task::Task, data)\n",
    "    if isempty(learner.parameters)\n",
    "        model = SModel(data[:, task.features], data[:, task.target])\n",
    "    else\n",
    "        parameters = []\n",
    "        push!(parameters, get_λ(learner.parameters, data))\n",
    "        model = SModel(data[:, task.features], data[:, task.target], L2DistLoss(), L2Penalty(), parameters...)\n",
    "    end\n",
    "    MLRModel(model, copy(learner.parameters))\n",
    "end\n",
    "\n",
    "function makeGlm(learner::Learner, task::Task, data)\n",
    "    if isempty(learner.parameters)\n",
    "        model = SModel(data[:, task.features], data[:, task.target])\n",
    "    else\n",
    "        parameters = []\n",
    "        if get(learner.parameters, \"λ\", false) !== false\n",
    "            # Add λ\n",
    "            push!(parameters, get_λ(learner.parameters, task))\n",
    "        end\n",
    "        if get(learner.parameters, \"penalty\", false) !== false\n",
    "            # Add penalty\n",
    "            push!(parameters, learner.parameters[\"penalty\"])\n",
    "        end\n",
    "        if get(learner.parameters, \"loss\", false) !== false\n",
    "            # Add penalty\n",
    "            push!(parameters, learner.parameters[\"loss\"])\n",
    "        end\n",
    "        model = SModel(data[:, task.features], data[:, task.target], parameters...)\n",
    "    end\n",
    "    MLRModel(model, copy(learner.parameters))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learnᵧ! (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### MODEL WRAPPERS ####\n",
    "using SparseRegression\n",
    "\n",
    "function get_λ(parameters, task)\n",
    "    if get(parameters, \"λ\", false) == false\n",
    "        lambda = fill(0.0, task.features)\n",
    "    elseif typeof(parameters[\"λ\"]) <: Real\n",
    "        lambda = fill(parameters[\"λ\"], length(task.features) )\n",
    "    elseif typeof(parameters[\"λ\"]) <: Vector{Float64}\n",
    "        lambda = copy(parameters[\"λ\"])\n",
    "    end\n",
    "    lambda\n",
    "end\n",
    "\n",
    "\n",
    "function predictᵧ(modelᵧ::MLRModel{<:SModel}; data=data, task=task)\n",
    "    predict(modelᵧ.model, data[:, task.features])\n",
    "end\n",
    "\n",
    "function learnᵧ!(modelᵧ::MLRModel{<:SModel}; learner=nothing::Learner, data=nothing::Matrix{Real}, task=nothing::Task)\n",
    "    learn!(modelᵧ.model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tune (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_parameters!(array, range) \n",
    "    array[1] += 1\n",
    "    for i in 1:length(array)\n",
    "        if array[i] > range[i][end]\n",
    "            array[i+1] += 1\n",
    "            array[i] = range[i][1]\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function parameters_dictionary(ps::ParametersSet, array, discrete_dictionary)\n",
    "    dict = Dict()\n",
    "    for i in 1:length(array)\n",
    "        if typeof(ps[i]) <: ContinuousParameter\n",
    "            dict[ps[i].name] = ps[i].transform( convert(Float64, array[i]) )\n",
    "        else\n",
    "            dict[ps[i].name] = discrete_dictionary[ps[i].name][array[i]]\n",
    "        end\n",
    "    end\n",
    "    dict\n",
    "end\n",
    "\n",
    "function get_samples(sampler::Resampling, n_obs::Int64)\n",
    "    trainᵢ = []\n",
    "    testᵢ = []\n",
    "    if sampler.method == \"KFold\"\n",
    "        kfold = Kfold(n_obs, sampler.iterations)\n",
    "        for train in kfold\n",
    "            push!(trainᵢ, collect(train))\n",
    "            push!(testᵢ, setdiff(1:n_obs, trainᵢ[end]))\n",
    "        end\n",
    "    end  \n",
    "    trainᵢ, testᵢ\n",
    "end\n",
    "\n",
    "function tune(;learner=nothing::Learner, task=nothing::Task, data=nothing::Matrix{Real}, \n",
    "                parameters_set=nothing::ParametersSet, sampler=Resampling()::Resampling, \n",
    "                measure=nothing::Function)\n",
    "    \n",
    "    n_parameters = length(parameters_set.parameters)\n",
    "    n_obs        = size(data,1)\n",
    "        \n",
    "    parameters_array = Array{Any}(n_parameters)\n",
    "    parameters_range = Array{Tuple}(n_parameters)\n",
    "    \n",
    "    # For discrete parameters, the range is set to 1:n_discrete_values\n",
    "    # The discrete dictionary variable allows to connect this range to \n",
    "    # the actual discrete value\n",
    "    discrete_dictionary = Dict()\n",
    "    \n",
    "    total_parameters = 1\n",
    "    \n",
    "    # Prepare parameters\n",
    "    for i in 1:n_parameters\n",
    "        if typeof(parameters_set[i]) <: ContinuousParameter \n",
    "            lower = parameters_set[i].lower\n",
    "            upper = parameters_set[i].upper\n",
    "            parameters_array[i] = lower\n",
    "            parameters_range[i] = Tuple(lower:upper)\n",
    "            params = length(lower:upper)\n",
    "        else\n",
    "            parameters_array[i] = 1\n",
    "            parameters_range[i] = Tuple(1:length(parameters_set[i].values))\n",
    "            discrete_dictionary[parameters_set[i].name] = parameters_set[i].values\n",
    "            params = length(parameters_set[i].values)\n",
    "        end\n",
    "        total_parameters *= params\n",
    "    end\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Loop over parameters\n",
    "    for i in 1:total_parameters\n",
    "        # Set new parametersparameters_set[i].values\n",
    "        update_parameters!(parameters_array, parameters_range) \n",
    "        pd = parameters_dictionary(parameters_set, parameters_array, discrete_dictionary)\n",
    "\n",
    "        # Update learner with new parameters\n",
    "        lrn = Learner(learner.name, pd)\n",
    "                \n",
    "        # Get training/testing validation sets\n",
    "        trainⱼ, testⱼ = get_samples(sampler, n_obs)\n",
    "        \n",
    "        scores = []\n",
    "        for j in 1:length(trainⱼ)  \n",
    "            modelᵧ = learnᵧ(lrn, task, data[trainⱼ[j], :])\n",
    "            preds = predictᵧ(modelᵧ, data=data[testⱼ[j],:], task=task)\n",
    "            \n",
    "            score = measure( data[testⱼ[j], task.target], preds)\n",
    "            push!(scores, score)\n",
    "        end\n",
    "        println(\"Trained:\")\n",
    "        println(lrn)\n",
    "        println(\"Average CV accuracy: $(mean(scores))\\n\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 18 iterations: [-0.68388, -1.38216, 0.878894]\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L1Penalty\n",
      " ▁ ▂ ▃ λ: 0.001\n",
      "\n",
      "Average CV accuracy: 3.3280955130486892e-6\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L1Penalty\n",
      " ▁ ▂ ▃ λ: 0.01\n",
      "\n",
      "Average CV accuracy: 0.0003592596315147756\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L1Penalty\n",
      " ▁ ▂ ▃ λ: 0.1\n",
      "\n",
      "Average CV accuracy: 0.04028597046451981\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L1Penalty\n",
      " ▁ ▂ ▃ λ: 1.0\n",
      "\n",
      "Average CV accuracy: 2.294579016910561\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L1Penalty\n",
      " ▁ ▂ ▃ λ: 10.0\n",
      "\n",
      "Average CV accuracy: 2.9276403421561685\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 18 iterations: [-0.683888, -1.38238, 0.879054]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 13 iterations: [-0.684047, -1.38228, 0.87909]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 17 iterations: [-0.672395, -1.37159, 0.870453]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 17 iterations: [-0.673906, -1.37175, 0.867849]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 16 iterations: [-0.676896, -1.37378, 0.869332]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 22 iterations: [-0.543055, -1.30089, 0.749015]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 23 iterations: [-0.59643, -1.24141, 0.769539]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 15 iterations: [-0.599445, -1.27581, 0.780547]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 12 iterations: [-0.0, -0.304757, 0.0]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 15 iterations: [-0.0, -0.333514, 0.0]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 13 iterations: [-0.0, -0.223772, 0.0]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 2 iterations: [-0.0, -0.0, 0.0]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 2 iterations: [-0.0, -0.0, 0.0]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mConverged after 2 iterations: [-0.0, -0.0, 0.0]\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ▁ ▂ ▃ penalty: L2Penalty\n",
      " ▁ ▂ ▃ λ: 0.0001\n",
      "\n",
      "Average CV accuracy: 3.604703416597752e-8\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L2Penalty\n",
      " ▁ ▂ ▃ λ: 0.001\n",
      "\n",
      "Average CV accuracy: 3.5925834875100503e-6\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L2Penalty\n",
      " ▁ ▂ ▃ λ: 0.01\n",
      "\n",
      "Average CV accuracy: 0.0003889354181530369\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L2Penalty\n",
      " ▁ ▂ ▃ λ: 0.1\n",
      "\n",
      "Average CV accuracy: 0.0375478154462754\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L2Penalty\n",
      " ▁ ▂ ▃ λ: 1.0\n",
      "\n",
      "Average CV accuracy: 0.8877517449758807\n",
      "\n",
      "Trained:\n",
      "Learner: glm\n",
      " ▁ ▂ ▃ penalty: L2Penalty\n",
      " ▁ ▂ ▃ λ: 10.0\n",
      "\n",
      "Average CV accuracy: 2.4757423479712064\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mSweep finished\n",
      "\u001b[39m"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mBoundsError: attempt to access 2-element Array{Any,1} at index [3]\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mBoundsError: attempt to access 2-element Array{Any,1} at index [3]\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1mupdate_parameters!\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Array{Tuple,1}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[8]:5\u001b[22m\u001b[22m",
      " [2] \u001b[1m#tune#8\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Learner, ::Task, ::Array{Float64,2}, ::ParametersSet, ::Resampling, ::MLMetrics.#mean_squared_error, ::Function\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./In[8]:75\u001b[22m\u001b[22m",
      " [3] \u001b[1m(::#kw##tune)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::#tune\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./<missing>:0\u001b[22m\u001b[22m",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "ps = ParametersSet([\n",
    "    ContinuousParameter(\n",
    "        name = \"λ\",\n",
    "        lower = -4,\n",
    "        upper = 1,\n",
    "        transform = x->10^x\n",
    "    )\n",
    "        ,\n",
    "    DiscreteParameter(\n",
    "        name = \"penalty\",\n",
    "        values = [L1Penalty(), L2Penalty()]\n",
    "    )\n",
    "])\n",
    "\n",
    "data = Fakedata(1000,3)\n",
    "\n",
    "task = Task(task_type=\"regression\", target=4, data=data)\n",
    "lrn = Learner(\"glm\")\n",
    "learnᵧ(lrn,task,data)\n",
    "tune(learner=lrn, task=task, data=data, parameters_set=ps, measure=mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: FakeData not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: FakeData not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:522\u001b[22m\u001b[22m"
     ]
    }
   ],
   "source": [
    "data = FakeData(1000,3)\n",
    "\n",
    "task = Task(task_type=\"regression\", target=4, data=data)\n",
    "lrn  = Learner(\"ridge\")\n",
    "\n",
    "train = 1:80\n",
    "test  = 81:100\n",
    "\n",
    "\n",
    "modelᵧ = learnᵧ(lrn, task, data[train,:])\n",
    "pred = predictᵧ(modelᵧ, data=data[test,:], task=task)\n",
    "\n",
    "mean_squared_error(data[test,task.target],pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tuple{Array{Float64,2},Array{Float64,1}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Dagger\n",
    "model = SModel(data[:, task.features], data[:, task.target])\n",
    "fun(a,b,c)=SModel(a,b,c)\n",
    "dc1=delayed(fun)(data[:, task.features], data[:, task.target])\n",
    "dc2=delayed(learn!)(model)\n",
    "typeof(dc1.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe data provider and maybe copy dagger graph mutliple times???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# What is the alternative\n",
    "g(x)=x\n",
    "setfield!(x->x^2,:g,Main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
