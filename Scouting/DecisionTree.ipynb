{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree.jl\n",
    "\n",
    "https://github.com/bensadeghi/DecisionTree.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Summary\n",
    "\n",
    "DecisionTree.jl implements decision tree classification and \n",
    "regression (regression is automatic if targets are float), this imcludes post pruning, random forests (parallelized bagging) and\n",
    "adaptive boosting. \n",
    "\n",
    "K-fold cross validation is built in for decision trees, forests and\n",
    "adaptive boosting models via *nFoldCV_forest(...)* etc.\n",
    "\n",
    "Additionally a ScikitLearn.jl API is included so calls can be made\n",
    "to *DecisionTreeClassifier* et al from ScikitLearn.jl\n",
    "\n",
    "The main models have similar usage e.g training with *model=build_tree(...)* and prediction with *apply_tree(model,...)* or\n",
    "probabilities with *apply_tree_proba(model,...)*.\n",
    "\n",
    "Perfomance is an issue when compared to python implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details\n",
    "\n",
    "| Test                      | Results                           |            \n",
    "| :- | :- |\n",
    "| Packages works            | yes                               |\n",
    "| Deprecation warnings      | None                              |\n",
    "| Compatible with JuliaDB   | If tables are converted to arrays |\n",
    "| Contains Documetation     | No, but many examples             |\n",
    "| Simplicity                | Good, like sklearn                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "build_tree\n",
    "    \n",
    "    Arguments: labels::Vector, features::Matrix, weights=[0];\n",
    "               rng=Base.GLOBAL_RNG\n",
    "\n",
    "print_tree\n",
    "\n",
    "    Arguments: leaf::Leaf, depth=-1, indent=0\n",
    "\n",
    "\n",
    "apply_tree\n",
    "    \n",
    "    Arguments: tree::Node, features::Vector\n",
    "    \n",
    "apply_tree_proba\n",
    "\n",
    "    Arguments: tree::LeafOrNode, features::Matrix, labels\n",
    "\n",
    "prune_tree\n",
    "\n",
    "    Arguments: tree::LeafOrNode, purity_thresh=1.0\n",
    "    \n",
    "build_stump\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, weights=[0];\n",
    "               rng=Base.GLOBAL_RNG\n",
    "\n",
    "build_forest\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, \n",
    "               nsubfeatures::Integer, ntrees::Integer, \n",
    "               partialsampling=0.7, maxdepth=-1; rng=Base.GLOBAL_RNG\n",
    "\n",
    "apply_forest\n",
    "\n",
    "    Arguments: forest::Ensemble, features::Vector\n",
    "    \n",
    "apply_forest_proba\n",
    "\n",
    "    Arguments: forest::Ensemble, features::Matrix, labels)\n",
    "\n",
    "build_adaboost_stumps\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, niterations::Integer; \n",
    "               rng=Base.GLOBAL_RNG\n",
    "\n",
    "apply_adaboost_stumps\n",
    "    \n",
    "    Arguments: stumps::Ensemble, coeffs::Vector{Float64}, \n",
    "               features::Vector\n",
    "               \n",
    "apply_adaboost_stumps_proba\n",
    "\n",
    "    Arguments: stumps::Ensemble, coeffs::Vector{Float64},\n",
    "               features::Vector, labels::Vector\n",
    "\n",
    "confusion_matrix\n",
    "\n",
    "    Arguments: actual::Vector, predicted::Vector\n",
    "\n",
    "nfoldCV_tree\n",
    "    \n",
    "    Arguments: labels::Vector, features::Matrix, pruning_purity::Real, \n",
    "               nfolds::Integer\n",
    "\n",
    "nfoldCV_forest\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, \n",
    "               nsubfeatures::Integer, ntrees::Integer, \n",
    "               nfolds::Integer, partialsampling=0.7\n",
    "\n",
    "nfoldCV_stumps\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, niterations::Integer,\n",
    "               nfolds::Integer\n",
    "               \n",
    "majority_vote\n",
    "\n",
    "    Arguments: labels::Vector\n",
    "    \n",
    "R2\n",
    "\n",
    "    Arguments: actual, predicted\n",
    "\n",
    "mean_squared_error\n",
    "\n",
    "    Arguments: actual, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Code\n",
    "\n",
    "Taken from the github examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Building a decision tree with pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0.0 1.0; 0.96 0.04; 1.0 0.0; 0.0 1.0; 1.0 0.0; 0.214286 0.785714; 0.214286 0.785714; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 1.0 0.0; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 1.0 0.0; 1.0 0.0; 0.0246914 0.975309; 0.96 0.04; 0.0 1.0; 0.0 1.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 0.3 0.7; 0.0 1.0; 0.8 0.2; 1.0 0.0; 1.0 0.0; 0.0 1.0; 1.0 0.0; 1.0 0.0; 0.0246914 0.975309; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 0.96 0.04; 0.96 0.04; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.75 0.25; 0.0246914 0.975309; 1.0 0.0; 0.0 1.0; 0.965517 0.0344828; 0.0246914 0.975309; 0.0 1.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 0.0246914 0.975309; 1.0 0.0; 0.833333 0.166667; 0.965517 0.0344828; 0.833333 0.166667; 1.0 0.0; 0.965517 0.0344828; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.965517 0.0344828; 1.0 0.0; 0.833333 0.166667; 0.833333 0.166667; 0.965517 0.0344828]\n"
     ]
    }
   ],
   "source": [
    "using DecisionTree\n",
    "include(\"load_titanic.jl\")\n",
    "X_train,T_train, X_test, T_test = load()\n",
    "\n",
    "# train full-tree classifier\n",
    "model = build_tree(T_train, X_train)\n",
    "# prune tree: merge leaves having >= 70% combined purity (default: 100%)\n",
    "model = prune_tree(model, 0.7)\n",
    "# apply learned model\n",
    "println(apply_tree(model, X_test))\n",
    "# get the probability of each label\n",
    "println(apply_tree_proba(model, X_test, [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Classes:  "
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 86  29\n",
       " 33  63"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "Matrix:   "
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 87  40\n",
       " 20  64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 102  30\n",
       "  27  52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7061611374407583\n",
      "Kappa:    0.40547173241228857\n",
      "\n",
      "Fold 2\n",
      "Classes:  [0, 1]\n",
      "Matrix:   \n",
      "Accuracy: 0.7156398104265402\n",
      "Kappa:    0.4296269598125787\n",
      "\n",
      "Fold 3\n",
      "Classes:  [0, 1]\n",
      "Matrix:   \n",
      "Accuracy: 0.7298578199052133\n",
      "Kappa:    0.42769450392576736\n",
      "\n",
      "Mean Accuracy: 0.7172195892575038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.706161\n",
       " 0.71564 \n",
       " 0.729858"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run n-fold cross validation for pruned tree,\n",
    "# using 90% purity threshold pruning, and 3 CV folds\n",
    "accuracy = nfoldCV_tree(T_train, X_train, 0.9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 3, Threshold 1.0\n",
      "L-> Feature 2, Threshold 3.0\n",
      "    L-> Feature 7, Threshold 29.0\n",
      "        L-> Feature 7, Threshold 28.7125\n",
      "            L-> Feature 4, Threshold 24.0\n",
      "                L-> 1 : 14/14\n",
      "                R-> \n",
      "            R-> 0 : 1/1\n",
      "        R-> 1 : 79/81\n",
      "    R-> Feature 7, Threshold 21.075\n",
      "        L-> Feature 4, Threshold 37.0\n",
      "            L-> Feature 6, Threshold 2.0\n",
      "                L-> \n",
      "                R-> 1 : 6/6\n",
      "            R-> 0 : 4/4\n",
      "        R-> Feature 1, Threshold 375.0\n",
      "            L-> Feature 1, Threshold 185.0\n",
      "                L-> 0 : 5/6\n",
      "                R-> 1 : 2/2\n",
      "            R-> 0 : 12/12\n",
      "R-> Feature 4, Threshold 10.0\n",
      "    L-> Feature 5, Threshold 3.0\n",
      "        L-> 1 : 17/17\n",
      "        R-> 0 : 10/10\n",
      "    R-> Feature 2, Threshold 2.0\n",
      "        L-> Feature 1, Threshold 391.0\n",
      "            L-> Feature 7, Threshold 66.6\n",
      "                L-> \n",
      "                R-> 0 : 13/13\n",
      "            R-> Feature 4, Threshold 58.0\n",
      "                L-> \n",
      "                R-> \n",
      "        R-> Feature 1, Threshold 677.0\n",
      "            L-> Feature 1, Threshold 674.0\n",
      "                L-> \n",
      "                R-> 1 : 1/1\n",
      "            R-> Feature 7, Threshold 56.4958\n",
      "                L-> \n",
      "                R-> 1 : 1/1\n"
     ]
    }
   ],
   "source": [
    "# pretty print of the tree, to a depth of 5 nodes (optional)\n",
    "print_tree(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "A simple benchmark training a random forest classifier with progressively more trees in each forest, and a decision tree\n",
    "with progressively more data instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0549153, 0.384804, 3.94297]"
     ]
    }
   ],
   "source": [
    "# I would strongly suggest not running past n=4\n",
    "n = 3\n",
    "Time = zeros(n)\n",
    "for i = 1:n\n",
    "    Time[i] = (@timed build_forest(T_train, X_train, 2, 10^i))[2]\n",
    "end\n",
    "print(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0203748\n",
       " 0.0234457\n",
       " 0.0639324"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# past 5 takes a while\n",
    "n=3\n",
    "Time = zeros(n)\n",
    "for i in 1:n\n",
    "    x,t = expand_data(X_train,T_train,10^i)\n",
    "    X = vcat(X_train,x)\n",
    "    T = vcat(T_train,t)\n",
    "    Time[i] = (@timed build_tree(T, X))[2]\n",
    "end\n",
    "Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "| Forest Size        | Julia            | Python |\n",
    "|:------:|:-------:|:-------:|\n",
    "| 10     | 0.0466s | 0.024s | \n",
    "| 100    | 0.389s  | 0.118s |\n",
    "| 1000   | 3.7s    | 1.04s  |\n",
    "| 10000  | 37.8s   | 11s    |\n",
    "| 100000 | 465s    | 110s    |\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "| Data Instances        | Julia            | Python |\n",
    "|:------:|:-------:|:-------:|\n",
    "| 654     | 0.0136s | 000258s | \n",
    "| 834    | 0.0238s  | 0.00265s |\n",
    "| 2634   | 0.0805s    | 0.00502s  |\n",
    "| 20634  | 0.621s   | 0.0196s    |\n",
    "| 200634 | 7.73s    | 0.180s    |\n",
    "| 2000634 | 132s    | 2.92s    |\n",
    "\n",
    "\n",
    "Clearly this Julia implementation is consistently slower than the\n",
    "corresponding sklearn package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "julia-pro 0.6.2",
   "language": "julia",
   "name": "julia-pro-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
