{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree.jl\n",
    "\n",
    "https://github.com/bensadeghi/DecisionTree.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "DecisionTree.jl implements decision tree classification and \n",
    "regression (regression is automatic if targets are float), this imcludes post pruning, random forests (parallelized bagging) and\n",
    "adaptive boosting. \n",
    "\n",
    "K-fold cross validation is built in for decision trees, forests and\n",
    "adaptive boosting models via *nFoldCV_forest(...)* etc.\n",
    "\n",
    "Additionally a ScikitLearn.jl API is included so calls can be made\n",
    "to *DecisionTreeClassifier* et al from ScikitLearn.jl\n",
    "\n",
    "The main models have similar usage e.g training with *model=build_tree(...)* and prediction with *apply_tree(model,...)* or\n",
    "probabilities with *apply_tree_proba(model,...)*.\n",
    "\n",
    "Perfomance is an issue when compared to python implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details\n",
    "\n",
    "| Test                      | Results                           |            \n",
    "| :- | :- |\n",
    "| Packages works            | yes                               |\n",
    "| Deprecation warnings      | None                              |\n",
    "| Compatible with JuliaDB   | If tables are converted to arrays |\n",
    "| Contains Documetation     | No, but many examples             |\n",
    "| Simplicity                | Good, like sklearn                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "build_tree\n",
    "    \n",
    "    Arguments: labels::Vector, features::Matrix, weights=[0];\n",
    "               rng=Base.GLOBAL_RNG\n",
    "\n",
    "print_tree\n",
    "\n",
    "    Arguments: leaf::Leaf, depth=-1, indent=0\n",
    "\n",
    "\n",
    "apply_tree\n",
    "    \n",
    "    Arguments: tree::Node, features::Vector\n",
    "    \n",
    "apply_tree_proba\n",
    "\n",
    "    Arguments: tree::LeafOrNode, features::Matrix, labels\n",
    "\n",
    "prune_tree\n",
    "\n",
    "    Arguments: tree::LeafOrNode, purity_thresh=1.0\n",
    "    \n",
    "build_stump\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, weights=[0];\n",
    "               rng=Base.GLOBAL_RNG\n",
    "\n",
    "build_forest\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, \n",
    "               nsubfeatures::Integer, ntrees::Integer, \n",
    "               partialsampling=0.7, maxdepth=-1; rng=Base.GLOBAL_RNG\n",
    "\n",
    "apply_forest\n",
    "\n",
    "    Arguments: forest::Ensemble, features::Vector\n",
    "    \n",
    "apply_forest_proba\n",
    "\n",
    "    Arguments: forest::Ensemble, features::Matrix, labels)\n",
    "\n",
    "build_adaboost_stumps\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, niterations::Integer; \n",
    "               rng=Base.GLOBAL_RNG\n",
    "\n",
    "apply_adaboost_stumps\n",
    "    \n",
    "    Arguments: stumps::Ensemble, coeffs::Vector{Float64}, \n",
    "               features::Vector\n",
    "               \n",
    "apply_adaboost_stumps_proba\n",
    "\n",
    "    Arguments: stumps::Ensemble, coeffs::Vector{Float64},\n",
    "               features::Vector, labels::Vector\n",
    "\n",
    "confusion_matrix\n",
    "\n",
    "    Arguments: actual::Vector, predicted::Vector\n",
    "\n",
    "nfoldCV_tree\n",
    "    \n",
    "    Arguments: labels::Vector, features::Matrix, pruning_purity::Real, \n",
    "               nfolds::Integer\n",
    "\n",
    "nfoldCV_forest\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, \n",
    "               nsubfeatures::Integer, ntrees::Integer, \n",
    "               nfolds::Integer, partialsampling=0.7\n",
    "\n",
    "nfoldCV_stumps\n",
    "\n",
    "    Arguments: labels::Vector, features::Matrix, niterations::Integer,\n",
    "               nfolds::Integer\n",
    "               \n",
    "majority_vote\n",
    "\n",
    "    Arguments: labels::Vector\n",
    "    \n",
    "R2\n",
    "\n",
    "    Arguments: actual, predicted\n",
    "\n",
    "mean_squared_error\n",
    "\n",
    "    Arguments: actual, predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Code\n",
    "\n",
    "Taken from the github examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Building a decision tree with pruning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any[1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0.0 1.0; 0.96 0.04; 1.0 0.0; 0.0 1.0; 1.0 0.0; 0.214286 0.785714; 0.214286 0.785714; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 1.0 0.0; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 1.0 0.0; 1.0 0.0; 0.0246914 0.975309; 0.96 0.04; 0.0 1.0; 0.0 1.0; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 0.3 0.7; 0.0 1.0; 0.8 0.2; 1.0 0.0; 1.0 0.0; 0.0 1.0; 1.0 0.0; 1.0 0.0; 0.0246914 0.975309; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 0.96 0.04; 0.96 0.04; 0.0246914 0.975309; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.75 0.25; 0.0246914 0.975309; 1.0 0.0; 0.0 1.0; 0.965517 0.0344828; 0.0246914 0.975309; 0.0 1.0; 1.0 0.0; 1.0 0.0; 0.0 1.0; 0.0246914 0.975309; 1.0 0.0; 0.833333 0.166667; 0.965517 0.0344828; 0.833333 0.166667; 1.0 0.0; 0.965517 0.0344828; 1.0 0.0; 1.0 0.0; 1.0 0.0; 0.965517 0.0344828; 1.0 0.0; 0.833333 0.166667; 0.833333 0.166667; 0.965517 0.0344828]\n"
     ]
    }
   ],
   "source": [
    "using DecisionTree\n",
    "include(\"load_titanic.jl\")\n",
    "X_train,T_train, X_test, T_test = load()\n",
    "\n",
    "# train full-tree classifier\n",
    "model = build_tree(T_train, X_train)\n",
    "# prune tree: merge leaves having >= 70% combined purity (default: 100%)\n",
    "model = prune_tree(model, 0.7)\n",
    "# apply learned model\n",
    "println(apply_tree(model, X_test))\n",
    "# get the probability of each label\n",
    "println(apply_tree_proba(model, X_test, [0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 95  27\n",
       " 28  61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 95  26\n",
       " 23  67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Int64,2}:\n",
       " 96  36\n",
       " 23  56"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Classes:  [0, 1]\n",
      "Matrix:   \n",
      "Accuracy: 0.7393364928909952\n",
      "Kappa:    0.46478808282986667\n",
      "\n",
      "Fold 2\n",
      "Classes:  [0, 1]\n",
      "Matrix:   \n",
      "Accuracy: 0.7677725118483413\n",
      "Kappa:    0.5273167832487542\n",
      "\n",
      "Fold 3\n",
      "Classes:  [0, 1]\n",
      "Matrix:   \n",
      "Accuracy: 0.7203791469194313\n",
      "Kappa:    0.4221861220700858\n",
      "\n",
      "Mean Accuracy: 0.7424960505529227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.739336\n",
       " 0.767773\n",
       " 0.720379"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run n-fold cross validation for pruned tree,\n",
    "# using 90% purity threshold pruning, and 3 CV folds\n",
    "accuracy = nfoldCV_tree(T_train, X_train, 0.9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Model visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 3, Threshold 1.0\n",
      "L-> Feature 2, Threshold 3.0\n",
      "    L-> Feature 7, Threshold 29.0\n",
      "        L-> Feature 7, Threshold 28.7125\n",
      "            L-> Feature 4, Threshold 24.0\n",
      "                L-> 1 : 14/14\n",
      "                R-> \n",
      "            R-> 0 : 1/1\n",
      "        R-> 1 : 79/81\n",
      "    R-> Feature 7, Threshold 21.075\n",
      "        L-> Feature 4, Threshold 37.0\n",
      "            L-> Feature 6, Threshold 2.0\n",
      "                L-> \n",
      "                R-> 1 : 6/6\n",
      "            R-> 0 : 4/4\n",
      "        R-> Feature 1, Threshold 375.0\n",
      "            L-> Feature 1, Threshold 185.0\n",
      "                L-> 0 : 5/6\n",
      "                R-> 1 : 2/2\n",
      "            R-> 0 : 12/12\n",
      "R-> Feature 4, Threshold 10.0\n",
      "    L-> Feature 5, Threshold 3.0\n",
      "        L-> 1 : 17/17\n",
      "        R-> 0 : 10/10\n",
      "    R-> Feature 2, Threshold 2.0\n",
      "        L-> Feature 1, Threshold 391.0\n",
      "            L-> Feature 7, Threshold 66.6\n",
      "                L-> \n",
      "                R-> 0 : 13/13\n",
      "            R-> Feature 4, Threshold 58.0\n",
      "                L-> \n",
      "                R-> \n",
      "        R-> Feature 1, Threshold 677.0\n",
      "            L-> Feature 1, Threshold 674.0\n",
      "                L-> \n",
      "                R-> 1 : 1/1\n",
      "            R-> Feature 7, Threshold 56.4958\n",
      "                L-> \n",
      "                R-> 1 : 1/1\n"
     ]
    }
   ],
   "source": [
    "# pretty print of the tree, to a depth of 5 nodes (optional)\n",
    "print_tree(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "A simple benchmark training a random forest classifier with progressively more trees in each forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0335964, 0.347403]"
     ]
    }
   ],
   "source": [
    "# I would strongly suggest not running past n=4\n",
    "n = 5\n",
    "Time = zeros(n)\n",
    "for i = 1:n\n",
    "    Time[i] = (@timed build_forest(T_train, X_train, 2, 10^i))[2]\n",
    "end\n",
    "print(Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "| Forest Size        | Julia            | Python |\n",
    "|:------:|:-------:|:-------:|\n",
    "| 10     | 0.0466s | 0.024s | \n",
    "| 100    | 0.389s  | 0.118s |\n",
    "| 1000   | 3.7s    | 1.04s  |\n",
    "| 10000  | 37.8s   | 11s    |\n",
    "| 100000 | 465s    | 110s    |\n",
    "\n",
    "Clearly this Julia implementation is consistently slower than the\n",
    "corresponding sklearn package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "julia-pro 0.6.2",
   "language": "julia",
   "name": "julia-pro-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
