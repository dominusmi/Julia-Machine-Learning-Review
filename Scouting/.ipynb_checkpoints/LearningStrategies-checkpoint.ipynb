{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Strategies\n",
    "\n",
    "## Summary\n",
    "\n",
    "Through the JuliaML _Learn.jl_ and _LearningStrategies.jl_, the Julia team built a framework allowing the simple implementation of new algorithms and learning strategies through the structure, and therefore also making it extremely simple to combine multiple strategies together.\n",
    "\n",
    "A strategy here simply means a way for the user to tell how a model (stored as a _struct_) is setup, trained and updated. This idea stems from the very similar property most learning algorithms operate with, which is:\n",
    "\n",
    "```julia\n",
    "# Learning a model involves a model, a strategy and (not necessary) some data    \n",
    "function learn!(model, strat::LearningStrategy, data)   \n",
    "    # We set up the model, can be preparing arrays for training, doing some preprocessing\n",
    "    setup!(strat, model[, data])           \n",
    "    \n",
    "    # Using the \"repeated\" function  on your data allows it to replicate it infinitely\n",
    "    for (i, item) in enumerate(data)                    \n",
    "    \n",
    "        # Update the model according to the strategy(-ies) and the data  \n",
    "        update!(model, strat[, i], item) \n",
    "        \n",
    "        # Allows to record information or generally \"hook in\" the process\n",
    "        hook(strat, model[, data], i)    \n",
    "        \n",
    "        # Checks if the finishing condition has been reached\n",
    "        finished(strat, model[, data], i) && break      \n",
    "    end\n",
    "    \n",
    "    # Clean up after yourself\n",
    "    cleanup!(strat, model) \n",
    "    \n",
    "    # Return the trained model\n",
    "    model                                               \n",
    "end\n",
    "```\n",
    "\n",
    "Which can be translated as setup, iterate over data until some end condition is met, and clean up.\n",
    "In addition, a conventional extra function which can (and should) be defined if your model is predictive, is _predict()_, with pseudocode\n",
    "\n",
    "```julia\n",
    "function predict(model, data)\n",
    "    # Make predictions\n",
    "end\n",
    "```\n",
    "\n",
    "## LearningStrategy\n",
    "\n",
    "A LearningStrategy is simply a struct which extends _LearningStrategy_. Through the dispatch-based way that Julia is built-on, a strategy needs not contain any variable, all that is required is that at least one of the following functions is defined:\n",
    "\n",
    "- `setup!(strat, model, data)`\n",
    "- `cleanup!(strat, model)`\n",
    "- `hook(strat, model, i)`\n",
    "- `finished(strat, model, data, i)`\n",
    "- `update!(model, strat, item)`\n",
    "\n",
    "Keep in mind of course that if only the `hook` function is defined for a generic strategy _StrategyA_, and this is the only strategy given for learning, the model will.. not learn anything!\n",
    "\n",
    "This architecture makes it extremely simple for user wanting to write his own learning algorithm to add methods as they come without need further planning. For instance, suppose one strats off by just implementing and `SGD()` optimizer, then all that would be required is to define the structure\n",
    "\n",
    "```julia\n",
    "struct SGD() <:LearningStrategy end\n",
    "```\n",
    "\n",
    "and then implement `update!(model, strategy::SGD()`. Later on, if the same user or another wants to implement _AdaProx_ optimizer, they can simply add a new function `update!(model, strategy::AdaProx)`.\n",
    "\n",
    "It is not even required to explicitely wirte a `learn!` function if all you need is the `update!`, simply use the call\n",
    "```julia\n",
    "learn!(model, SGD(), data)\n",
    "```\n",
    "and Julia will handle the \"missing\" functions (by simply passing them) and will maek the call to the update you defined.\n",
    "\n",
    "**Note:** the _data_ (and _i_)parameter is not actually required, all the base functions are defined with both data and no data argument\n",
    "\n",
    "## Meta-Strategy\n",
    "\n",
    "One extremely powerful feature that this framework offers is the combination of strategies. For instance, while only one strategy will tell the model how to train and update for each iteration, extra strategies which only give side indications can be very easily used. For instance, one of the built-in strategies is `MaxIter(n=100)` which, if given in conjuction to a laerning strategy for any model, will \"hook on\" to the _finished_ function, and will do its own check as to whether the algorithm is indeed over. A simple use would be:\n",
    "\n",
    "```julia\n",
    "learn!(MyModel(), strategies( MyLearningStrategy(), MaxIter(20) ), MyData )\n",
    "```\n",
    "\n",
    "In this way, the learning process will end after 20 iterations, even if the conditions for _finished()_ given by the _MyLearningStrategy_ are not met (only one _finished_ condition needs to be met for the learning to stop)\n",
    "\n",
    "This means that if you develop your own learning model, you do not need to also add all this \"side functionalities\"! How great is that!\n",
    "\n",
    "## Example Code\n",
    "\n",
    "### Making a simple maximum finder\n",
    "\n",
    "Below I will show a and explain a code to make a simple (and not very good..) maximum finder!\n",
    "The idea is this: the model will simply include a starting point (2D space), and a _heuristic function_ that is being optimised by a (bad) strategy.\n",
    "\n",
    "First thing first, since we're going to be implementing `learn!, update!` and `finished`, we need to export them from the base package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LearningStrategies\n",
    "import LearningStrategies: setup!, learn!, update!, finished, hook\n",
    "import Base.Iterators: repeated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the model. It contains 4 attributes, one of which is a generic function. x & y are the starting points, and z will just keep track of the current \"height\" (i.e. score) in the solution space. The _heuristic_ is the function to be optimised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct HillClimber\n",
    "    x::Float64\n",
    "    y::Float64\n",
    "    z::Float64\n",
    "    heuristic::Function\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define our learning strategy structure. Since this strategy doesn't require any attributes, its definition is trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct SillyOptimizer <: LearningStrategy end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we start the actual strategy building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finished (generic function with 13 methods)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update!(model::HillClimber, s::SillyOptimizer)\n",
    "    # Generate 4 random direction vectors\n",
    "    choices = rand((4,2))-0.5\n",
    "\n",
    "    # Normalizes to unit step size\n",
    "    choices ./= abs.(sum(choices,2))\n",
    "\n",
    "    # Test the locations\n",
    "    heights = [heuristic(choices[i,:]+[model.x,model.y]) for i in 1:size(choices,1)]\n",
    "    \n",
    "    # Keep the best\n",
    "    (model.z, best) = findmax(heights)\n",
    "    \n",
    "    # Change current coordinates\n",
    "    model.x += choices[best,1]\n",
    "    model.y += choices[best,2]\n",
    "end\n",
    "\n",
    "# Stop after first iteration\n",
    "finished(s::SillyOptimizer, model) = true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that the `learn!` did not actually need to be defined since there is no need for a setup, cleanup or hook. The finished simply returns true, hence it will complete after one iteration. Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HillClimber(1.8457752866121817, -1.3457752866121817, 0.3198406349543606, heuristic)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian with max at (0,1)\n",
    "function heuristic(x)\n",
    "    arg = (x[1])^2 /5 + (x[2]-1)^2 /12\n",
    "    h = exp(-arg)\n",
    "    h\n",
    "end\n",
    "\n",
    "# Create the model, giving the attributes in order of definition\n",
    "model = HillClimber(1.5, -2, 0, heuristic)\n",
    "\n",
    "# Learn!\n",
    "learn!(model, SillyOptimizer() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So given that it's a pretty bad optimiser and that we only allowed for one iteration, it didn't perform very well..\n",
    "Now it's quite hard for such an optimizer to decide when to stop and building a finished function. Therefore, what I will do is intead use meta-learning to decide when to finish. \n",
    "\n",
    "To do this, I first need to redefine `finished` so that it doesn't return true, and then use a convergence strategy, such as MaxIter or TimeLimit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HillClimber(-1.2859005428386339, 0.7859005428386331, 0.7156758609625664, heuristic)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine to never finish (careful here! #infiniteloop)\n",
    "finished(s::SillyOptimizer, model) = false\n",
    "\n",
    "# Create the model, giving the attributes in order of definition\n",
    "model = HillClimber(1.5, -2, 0, heuristic)\n",
    "\n",
    "# Use MaxIter to decide when to end learning\n",
    "learn!(model, strategy( SillyOptimizer(), MaxIter(20) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a helper strategy\n",
    "\n",
    "Now it's quite hard to tell whether it's actually working any good given the optimizer is quite bad and will keep moving even when it reaches a maximum, therefore I'd like to be able to visualise.. \n",
    "\n",
    "Why not build a path tracing strategy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update! (generic function with 6 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One array for each coordinate to keep track of positions\n",
    "mutable struct PathTracer <: LearningStrategy\n",
    "    x::Array{Float64}\n",
    "    y::Array{Float64}\n",
    "    z::Array{Float64}\n",
    "end\n",
    "\n",
    "# The constructor (for any argument) is simply to initialise the arrays\n",
    "PathTracer() = PathTracer([],[],[])\n",
    "\n",
    "# On setup, save initial position\n",
    "function setup!(s::PathTracer, model::HillClimber)\n",
    "   update!(model, s) \n",
    "end\n",
    "\n",
    "# Save current position\n",
    "function update!(model::HillClimber, s::PathTracer)\n",
    "    push!(s.x, model.x)\n",
    "    push!(s.y, model.y)\n",
    "    push!(s.z, model.z)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HillClimber(-0.579420674501785, 1.7794206745017853, 0.8889001390889367, heuristic)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model again, this time adding the path tracer strategy\n",
    "model = HillClimber(2.0, -4.8, 0.0, heuristic)\n",
    "tracer = PathTracer()\n",
    "learn!(model, strategy(SillyOptimizer(), MaxIter(30), tracer) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "using Plots\n",
    "pyplot()\n",
    "xs = linspace(-3,3,30)\n",
    "ys = linspace(-5,5,30)\n",
    "z = [heuristic([x, y]) for x=xs, y=ys]'\n",
    "\n",
    "anim = @animate for max_length = 2:length(tracer.x)-1\n",
    "    plot(xs, ys, z)\n",
    "    for i in 1:max_length\n",
    "        plot!([tracer.x[i], tracer.x[i+1]], [tracer.y[i], tracer.y[i+1]], arrow = true, color=\"black\")\n",
    "    end\n",
    "    plot!(legend=false, cb=false, title=\"SillyOptimizer Trace\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SillyOptimizer](resources/SillyOptimizer.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work quite well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hook Strategy\n",
    "\n",
    "The `hook` method is another method allowed in the framework, which should mostly be using for printing or logging. Nevertheless, here is a small example of what could be done with it: showing the current iteration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hook (generic function with 7 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the structure \n",
    "mutable struct Iteration <: LearningStrategy\n",
    "    n::Int\n",
    "end\n",
    "\n",
    "# Make the constructor always initialise to iteration 0\n",
    "Iteration() = Iteration(0)\n",
    "\n",
    "# Simple function to make nice priting\n",
    "Base.show(io::IO, s::Iteration) = print(io, \"Iteration: $(s.n)\")\n",
    "\n",
    "# The main culprit\n",
    "function hook(s::Iteration, model, .. )\n",
    "    info(s)\n",
    "    s.n+=1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting in a quite horrible logging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 0\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 1\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 2\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 3\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 4\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 5\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 6\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 7\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 8\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 9\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 10\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 11\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 12\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 13\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mIteration: 14\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(15) finished\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HillClimber(-0.11219219656952917, 0.3121921965695291, 0.9589266282140106, heuristic)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the model again, this time adding the path tracer strategy\n",
    "model = HillClimber(2.0, -4.8, 0.0, heuristic)\n",
    "tracer = PathTracer()\n",
    "learn!(model, Verbose(strategy(SillyOptimizer(), MaxIter(15), tracer, Iteration())) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
