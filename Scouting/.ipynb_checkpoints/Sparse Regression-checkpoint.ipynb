{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparseRegression.jl\n",
    "Git: https://github.com/joshday/SparseRegression.jl\n",
    "\n",
    "---\n",
    "\n",
    "#### Summary\n",
    "Sparse regression is a package to achieve high performance regression of linear models for large dataset where coefficients often turn out to be sparse.\n",
    "The main call follows the form SModel(x,y, args) where arguments include the loss, penalty, and the $\\lambda$ and $\\omega$ arguments.\n",
    "Prediction are done through *predict(X, model)* call\n",
    "\n",
    "The loss and penalty functions are based on the _LossFunctions_ and _PenaltyFunctions_ MLJulia core packages.\n",
    "\n",
    "Additionally, one can use learning strategies from the _LearningStategies_ package. This allows to set parameters that are purely learning based, such as optimizers, max iterations or max items. \n",
    "More on this in the documentation.\n",
    "\n",
    "This structure allows for one model to be used for the many linear models such as OLS, ridge, lasso etc. which all have the same underlying structure.\n",
    "\n",
    "Issues: Seems to lose performance quite strongly when dimensionality increases, see benchmark at the bottom\n",
    "\n",
    "---\n",
    "#### Details\n",
    "\n",
    "| Test        | Results           \n",
    "| ------------- |:-------------:|\n",
    "| Package works | yes |\n",
    "| Deprecations warnings      | No      |\n",
    "| Compatible with JuliaDB | If targets transformed into array |\n",
    "| Contains documentation | yes, but not great |\n",
    "| Simplicity | good |\n",
    "\n",
    "\n",
    "---\n",
    "#### Usage\n",
    "\n",
    "\n",
    "SModel(x, y, args...)\n",
    "\n",
    "Arguments\n",
    "\n",
    "- loss::Loss = .5 * L2DistLoss()\n",
    "\n",
    "- penalty::Penalty = L2Penalty()\n",
    "\n",
    "- λ::Vector{Float64} = fill(size(x, 2), .1)\n",
    "\n",
    "- w::Union{Void, AbstractWeights} = nothing\n",
    "\n",
    "---\n",
    "\n",
    "#### Differences with Python's scikit-learn\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "#### Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SparseRegression;\n",
    "include(\"load_titanic.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(100) finished\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "█ SModel\n",
       "  > β        : [2.52083e74 -4.01126e74 … -2.42626e75 -1.07446e73]\n",
       "  > λ factor : [0.1 0.1 … 0.1 0.1]\n",
       "  > Loss     : L2DistLoss\n",
       "  > Penalty  : L1Penalty\n",
       "  > Data\n",
       "    - x : 634×8 Array{Float64,2}\n",
       "    - y : 634-element Array{Int64,1}\n",
       "    - w : Void"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example using lasso regression\n",
    "model = SModel(X_train,y_train, L2DistLoss(), L1Penalty());\n",
    "learn!(model);\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting new data\n",
    "predict(model, X_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Simple benchmark vs python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Only lasso regression is tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_regression (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_regression(n_points::Int64, n_dims::Int64)\n",
    "    x = randn(n_points, n_dims);\n",
    "    y = x * linspace(-1, 1, n_dims) + randn(n_points);\n",
    "    s = SModel(x, y, L2DistLoss(), L1Penalty(), λ=fill(size(x, 2), 1.0));\n",
    "\n",
    "    tic();\n",
    "    learn!(s);\n",
    "    time = toc();\n",
    "   \n",
    "    return time\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 4.714260026 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(100) finished\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 4.603028853 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(100) finished\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 4.645571737 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(100) finished\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 4.666341723 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(100) finished\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 4.616770439 seconds\n",
      "Average time 4.6491945556 for 5000 dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(100) finished\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IJulia.set_verbose(false)\n",
    "\n",
    "n_points = 10_000\n",
    "n_dims = [10, 100, 1000, 5000]\n",
    "\n",
    "avg_times = []\n",
    "\n",
    "for n_dim in n_dims\n",
    "    times = []\n",
    "    for i in 1:5\n",
    "        time = compute_regression(n_points, n_dim);\n",
    "        \n",
    "        push!(times, time);\n",
    "    end\n",
    "    avg_times = mean(times);\n",
    "    println(\"Average time $(avg_times) for $(n_dim) dimensions\")\n",
    "end\n",
    "\n",
    "IJulia.set_verbose(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "| Dimensions    | Julia | Python    \n",
    "| ------------- |:-----:|:-----:|\n",
    "| 10 | 0.00086s | 0.023s |\n",
    "| 100 | 0.0097s | 0.19s |\n",
    "| 1000 | 0.96s | 2.3s|\n",
    "| 5000 | 4.65s | 17s|\n",
    "\n",
    "The code for the python's results can be found in *python_scripts.py*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
