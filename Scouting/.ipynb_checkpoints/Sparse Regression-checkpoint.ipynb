{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparseRegression.jl\n",
    "Git: https://github.com/joshday/SparseRegression.jl\n",
    "\n",
    "---\n",
    "\n",
    "#### Summary\n",
    "Sparse regression is a package to achieve high performance regression of linear models for large dataset where coefficients often turn out to be sparse.\n",
    "The main call follows the form SModel(x,y, args) where arguments include the loss, penalty, and the $\\lambda$ and $\\omega$ arguments.\n",
    "Prediction are done through *predict(X, model)* call\n",
    "\n",
    "The loss and penalty functions are based on the _LossFunctions_ and _PenaltyFunctions_ MLJulia core packages.\n",
    "\n",
    "Additionally, one can use learning strategies from the _LearningStategies_ package. This allows to set parameters that are purely learning based, such as optimizers, max iterations or max items. \n",
    "More on this in the documentation.\n",
    "\n",
    "Tis structure allows for one model to be used for the many linear models such as OLS, ridge, lasso etc. which all have the same underlying structure.\n",
    "\n",
    "---\n",
    "#### Details\n",
    "\n",
    "| Test        | Results           \n",
    "| ------------- |:-------------:|\n",
    "| Package works | yes |\n",
    "| Deprecations warnings      | No      |\n",
    "| Compatible with JuliaDB | If targets transformed into array |\n",
    "| Contains documentation | yes, but not great |\n",
    "| Simplicity | good |\n",
    "\n",
    "\n",
    "---\n",
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using SparseRegression;\n",
    "include(\"load_titanic.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMaxIter(100) finished\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "# Example using lasso regression\n",
    "model = SModel(X_train,y_train, L2DistLoss(), L1Penalty());\n",
    "learn!(model);\n",
    "model\n",
    "\n",
    "# Example using ridge regression\n",
    "# model = SModel(X_train,y_train, L2DistLoss(), Î±*L1Penalty());\n",
    "# learn!(model);\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Simple benchmark vs python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Only lasso regression is tested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell takes ~5mins to run on my laptop, I would suggest trusting the results listed below instead of trying to run it.\n",
    "IJulia.set_verbose(false)\n",
    "\n",
    "n_points = 10_000\n",
    "n_dims = [5000]\n",
    "\n",
    "avg_times = []\n",
    "\n",
    "for n_dim in n_dims\n",
    "    times = []\n",
    "    for i in 1:5\n",
    "        x = randn(n_points, n_dim);\n",
    "        y = x * linspace(-1, 1, n_dim) + randn(n_points);\n",
    "        s = SModel(x, y);\n",
    "\n",
    "        tic();\n",
    "        learn!(s);\n",
    "        time = toc();\n",
    "        \n",
    "        push!(times, time);\n",
    "    end\n",
    "    avg_times = mean(times);\n",
    "end\n",
    "\n",
    "IJulia.set_verbose(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "| Dimensions    | Julia | Python    \n",
    "| ------------- |:-----:|:-----:|\n",
    "| 10 | 0.00055s | 0.023s |\n",
    "| 100 | 0.0073s | 0.19s |\n",
    "| 1000 | 0.29s | 2.05s|\n",
    "| 5000 | 58s | 17.68|\n",
    "\n",
    "Clearly, something goes wrong with the package when dimensions increase over a certain threshold, while python's performances seem to increase as expected.\n",
    "The code for the python's results can be found in *python_scripts.py*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
